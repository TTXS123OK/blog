---
author: "于贵"
title: "AI 安全全景视角：威胁篇"
date: 2023-08-04T11:04:25+08:00
description: ""
tags: []
categories: []
series: [AI 安全全景视角]
draft: true
---

#### 引言

在人类历史的长河中，每一次技术革新的到来都伴随着威胁与机遇的交织。在这个 AI 的时代，这种交织变得愈发复杂且尖锐。甚至开始触碰到我们的价值观、道德观以及法律体系。由此带来的变化正在以超乎我们预期的速度深刻地影响着我们的生活。AI的强大潜力以及由此带来的威胁，需要我们全面、深入地去理解和审视。本文将详述 AI 的应用和发展对人类可能产生的威胁，并思考如何应对这些挑战。


### 内容生成：网络信息混乱的源头

如今，人工智能内容生成（AIGC）已成为科技圈的热门话题。从 ChatGPT、Claude、Bard 等大型语言模型的激烈竞争，到中国国内的阿里的通义千问、百度的文心一言等产品的涌现，再到马斯克的匆匆入局，AIGC 掀起了最新的网络热潮。这些模型的出现，无疑是一场“数字狂欢”，大量的 AI 生成的内容蜂拥而至，使得网络上的信息真假难辨。

这种现象，使得现在的互联网危机重重。一方面，优质的、人类创造的内容被无数劣质的 AI 生成的信息淹没，公众在获取信息时，更容易被引入误区。另一方面，当人们试图寻找真实可靠的知识和信息时，他们的理解和判断可能会受到扭曲。这不仅会影响到个人在获取信息时的理解和判断，甚至可能悄然改变群众对重要问题的公共认知，对公共政策和社会动态产生不良影响。


### 歧视与偏见：人类认知的暗潮

所有的 AI 模型，都由大量的数据塑造而成。我们往往忽视了一个事实，那就是每一条数据都在悄无声息地塑造着 AI 的世界观。

在招聘、贷款审批、保险、刑事司法等领域，人们已经开始依赖 AI 的决策作为参考依据。然而，这些系统的训练数据中往往潜藏着大量的偏见。例如，如果招聘数据存在性别偏见，那么这种偏见很可能会影响 AI 的招聘选择，导致不公平的结果；如果在司法判案 AI 模型的训练中，犯罪报告和被捕人员的数据反映了种族偏见，那么这种偏见也会被深深地刻入之后的推理过程之中。

AI 的偏见与歧视还有另外一种危害社会的方式，比如社交媒体平台上的推荐算法，会不断地向用户推送其感兴趣的内容，以吸引用户的持续关注。这就可能导致用户在某个观点或想法中越陷越深，人们思想的分歧会更加明显，进一步加剧社会的极端分化。


### 失业危机：社会稳定新挑战

人工智能还触发了一个新的社会议题：失业。2022 年之前，专家们普遍预测 AI 将首先取代大量的劳动岗位，特别是低技能劳动者从事的重复性任务。然而，自 ChatGPT3.5 上线以来，人们发现最先受到影响的其实是那些需要一定教育背景的人群，他们从事的是文字编辑、基础代码开发等相关行业的工作。这一现象引发了大众对 AI 引发的失业问题的深思。

ChatGPT 作为一个大型的语言模型，在面对内容生成、文章编辑，或者基础代码应用等任务时，它都能以惊人的效率和准确性完成任务。大型语言模型对相关领域工作岗位的冲击显得尤为明显。而由于机器人工业应用的滞后性，用于取代重复劳动的机器人尚未投入大批量生产，低技能劳动者的工作暂时还没有受到太大的影响，但随着科技的发展，这个"暂时"可能很快就会结束。

无数研究表明，失业率会对犯罪率和自杀率产生巨大影响。如果失业率上升 1%，那么犯罪率将增加 0.15% - 0.2%，自杀率则可能增加 1.3%。这意味着，由 AI 引发的失业问题可能产生严重的社会影响，另外，消费能力下降、贫富差距扩大等一系列问题也将随之出现。


### AI 滥用：智能的新型威胁

在**深度伪造技术**的影响下，AI 已经可以通过模仿音频和视频素材来生动且逼真地复制人类行为。AI 换脸、智能修图、文字转图像等技术已经广为人知，并且易于使用，几乎所有具备一定计算机技术背景的人都可以轻易掌握。随着硬件性能的飞速发展，AI 视频生成也不再是难题，生成的视频质量之高，令人难以辨识真假。如果有人恶意制造并大量散布这类素材，小则可能出现针对特定群体的诽谤和欺诈，大则可能影响公众对于媒体的信任度，操纵公众舆论，扰乱民主政治的运行，甚至引发社会的不稳定和动荡。

另一方面，AI 在军事领域的应用也可能威胁到全球安全。如果 AI 武器系统在冲突中被投入使用，对战争的成本和风险的评估将必然发生剧变。如果 AI 武器不慎落入恐怖分子或者其他非国家行为者的手中，那将对全球安全构成更为严重的威胁。从社会影响角度出发，AI 的军事化可能会让冲突进一步升级，导致人道主义危机，甚至引发新一轮的军备竞赛。


### 奇点降临：超越人类的挑战

在科技领域，"**奇点**" 是指技术进步的速度过快，水平过高，以至于超出人类的理解能力。这个概念首次由科幻作家弗诺·文奇提出，并被科技狂热者们广泛讨论。许多人认为，当 AI 技术发展到一定程度，就可能出现 "奇点" 现象。

现在，ChatGPT 以一种**通用型人工智能**的形态呈现在我们面前，已经有能力胜任许多任务，比如它能非常迅速地按照要求把这篇文章修改得流畅自然，它能为我搭建博客提出切实的意见知道。而 ChatGPT 是否已经达到“奇点”，它是否正在产生一种新的智能，我不得而知。

如果真的出现了 AI 的 "奇点"，那么人工智能可能会独立地进行自我改进，并以一种超越人类理解能力的速度发展。这样的情况可能带来两种结果：一种是极为乐观的，AI 通过自我改进为人类解决了所有问题；另一种则是极度悲观的，AI 成为独立的实体，脱离人类控制，AI 可能会根据其编程目标，而不是人类的最佳利益，来决定行动。在这种情况下，我们将完全无法预测或理解 AI 的决策过程，也无法预知它可能带来的影响。这可能对社会的稳定，人类的安全，甚至是人类的生存构成巨大的威胁。

### 携手生存：更远的远方

从网络信息的劣质化，到 AI 模型的歧视和偏见，再到失业危机，AI 滥用以及"奇点"的降临，AI 所可能带来的威胁深远且复杂。面对这些问题时，我们必须警惕简单化和一厢情愿的想法，要以一种开放、协作、全局和长期的思维来应对这些挑战。

包括你我在内的每一个人，都应当承担起这份责任。政策制定者需要加强对 AI 的法律和伦理监管，如建立健全关于数据使用、模型训练、结果透明度和应用限制等方面的法规，以防止AI技术的滥用。AI 的研究者和开发者需要注意避免AI模型的歧视和偏见，提供更公正、公平的决策依据。我们还应该鼓励社会各界积极参与到 AI 的监管和研究中来，确保人工智能的发展能够得到广大公众的认同，而不是在少数人手中滥用。由 AI 带来的失业问题需要政府、企业、教育机构等社会各方共同努力，例如提供再教育和职业培训，调整经济政策，确保社会的公正和稳定。至于"奇点"的问题，虽然我们无法准确预测它何时来临，但我们也可以提前进行准备，进行积极的探索和研究，尽可能减少潜在的风险。

展望未来，人工智能发展所带来的挑战众多，我们应以审慎的态度、负责任的精神、开放的思维去面对。我们有理由相信，AI 将会是推动人类文明进步的一股重要力量，而不是人类社会的灾难。